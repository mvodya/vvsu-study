# Разметка изображений и обучение нейронной сети YOLO для детектирования объектов

## Основы детектирования объектов

**Детектирование объектов (Object Detection)** - это задача компьютерного зрения, в которой требуется не только определить, что изображено на картинке (классификация), но и *где именно* находится каждый объект

Результатом работы детектора являются:

* **координаты прямоугольника (bounding box)** вокруг объекта
* **метка класса** (например, "волк", "заяц")
* **достоверность (confidence)** - вероятность того, что найденный объект действительно принадлежит этому классу

Современные методы используют **сверточные нейронные сети (CNN)**, которые выделяют признаки объектов (feature maps) и обучаются предсказывать их расположение и тип

## Label Studio - система для разметки данных

**Label Studio** - это кроссплатформенный инструмент для аннотирования данных всех типов: изображений, видео, текста, аудио

Что умеет:

* Поддержка форматов разметки: **YOLO, COCO, Pascal VOC, JSON, CSV** и др.
* Гибкий интерфейс: можно рисовать **bounding boxes**, **полигоны**, **mask-области**, **текстовые метки**
* Экспорт разметки в формате, готовом для обучения

При экспорте Label Studio создает для каждого изображения файл с расширением `.txt`

Каждая строка в нем содержит:

```
<class_id> <x_center> <y_center> <width> <height>
```

Все координаты **нормализованы** в диапазоне `[0, 1]` и задаются относительно размеров изображения. Например:

```
0 0.52 0.47 0.30 0.25
```

означает:

* класс 0 (например, "волк");
* центр прямоугольника - 52 % по x и 47 % по y;
* ширина 30 %, высота 25 % от размеров изображения.

## Формирование и разделение датасетаы

Чтобы модель обучалась корректно, данные делят на **три части**:

* **train (обучающая выборка)** - основная часть данных (~ 70 %)
* **val (валидационная)** - для проверки качества обучения (~ 20 %)
* **test (тестовая)** - для итоговой оценки модели (~ 10 %)

Такое разделение предотвращает переобучение и позволяет объективно измерять качество на данных, которых модель не видела

### Структура проекта

```
dataset/
 ├── images/
 │    ├── train/
 │    ├── val/
 │    └── test/
 └── labels/
      ├── train/
      ├── val/
      └── test/
```

Файлы в `images/` и `labels/` должны совпадать по именам и относиться к тем же наборам

## Архитектура YOLO: принципы работы

### Концепция YOLO ("You Only Look Once")

YOLO - это семейство моделей, которые выполняют детектирование за **один проход сети**

В отличие от старых методов (R-CNN, Faster R-CNN), YOLO не сканирует картинку множество раз, а делит ее на сетку N x N, в каждой ячейке которой сеть предсказывает:

* координаты возможных объектов
* размеры bounding box
* вероятности классов

Такой подход обеспечивает **высокую скорость (реальное время)** и хорошую точность

### Этапы обработки

1. **Backbone** - сверточная часть, извлекающая признаки (feature maps)
2. **Neck** - объединяет признаки разных масштабов (PAN/FPN)
3. **Head** - предсказывает bounding boxes, классы и confidence-оценку

## Конфигурационный файл `data.yaml`

YOLO использует YAML-файл, где задаются пути и классы:

```yaml
path: ./dataset
train: images/train
val: images/val
test: images/test

names:
  0: wolf
  1: hare
```

Модель читает оттуда относительные пути и знает, какие ID соответствуют каким классам

## Этап обучения

### Подготовка среды

Устанавливается пакет `ultralytics`:

```bash
pip install ultralytics
```

В Python:

```python
from ultralytics import YOLO
model = YOLO("yolov8n.pt")
model.train(data="data.yaml", epochs=100, imgsz=640)
```

### Что происходит во время обучения

* Изображения из train-папки подаются мини-батчами (обычно 16–64 штук)
* Сеть корректирует веса, минимизируя **loss** - функцию ошибки, учитывающую три части:

  * ошибку координат,
  * ошибку размеров,
  * ошибку классификации.
* На каждом эпохе выводятся метрики: `box_loss`, `cls_loss`, `dfl_loss`, `mAP50`, `mAP50-95`
* После завершения сохраняются лучшие веса в `runs/detect/train*/best.pt`

## Проверка и использование модели

После обучения:

```python
model.val()  # оценка на валидационном наборе
```

Для применения на изображении или видео:

```python
results = model.predict(source="video.mp4", show=True)
```

YOLO выдает результаты - прямоугольники с подписями классов и вероятностями

Кадры можно сохранять автоматически: результаты помещаются в `runs/detect/predict*/`

## Метрики оценки качества

| Метрика          | Обозначение                    | Смысл                                                   |
| ---------------- | ------------------------------ | ------------------------------------------------------- |
| **Precision**    | TP / (TP + FP)                 | доля правильно найденных объектов среди всех найденных  |
| **Recall**       | TP / (TP + FN)                 | доля найденных объектов среди всех реально существующих |
| **mAP@0.5**      | средняя точность при IoU ≥ 0.5 | усредненная оценка по всем классам                      |
| **mAP@0.5–0.95** | интегральная метрика           | более строгая, усредняет по порогам IoU от 0.5 до 0.95  |

*(IoU - Intersection over Union, мера пересечения предсказанного и реального прямоугольников)*

## Проблемы и рекомендации

1. **Несбалансированные классы** - при малом числе примеров одного класса модель "забывает" его. Решение - добавить больше образцов или использовать аугментацию
2. **Переобучение** - снижается loss на train, но растет на val. Решение - регуляризация, Dropout, уменьшение эпох
3. **Малые объекты** - увеличить разрешение (`imgsz`) или использовать модель `yolov8l`
4. **Плохая разметка** - основная причина низкого качества. Следует проверять совпадение файлов и точность bounding box

## Автоматизация пайплайна (не требуется для лабораторной)

Полный цикл (pipeline):

1. Сбор данных -> Разметка в Label Studio ->
2. Экспорт YOLO -> Формирование структуры ->
3. Обучение YOLOv8 -> Тестирование и валидация ->
4. Анализ метрик и улучшение датасета.

В реальных проектах эти шаги оформляют как скрипты (dataset prep, train.py, eval.py), чтобы можно было переобучать модель при поступлении новых данных
